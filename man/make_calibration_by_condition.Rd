% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calibration_functions.R
\name{make_calibration_by_condition}
\alias{make_calibration_by_condition}
\title{Compute Calibration Statistics by Condition}
\usage{
make_calibration_by_condition(
  data,
  condition_vars,
  confidence_bins = NULL,
  choosers_only = TRUE,
  lineup_size = 6
)
}
\arguments{
\item{data}{A dataframe with columns: target_present, identification, confidence,
plus one or more condition variables}

\item{condition_vars}{Character vector of column names defining conditions
(e.g., c("instruction_type", "foil_similarity"))}

\item{confidence_bins}{Numeric vector of bin edges (optional)}

\item{choosers_only}{Logical. Whether to analyze only suspect IDs (default = TRUE)}

\item{lineup_size}{Integer. Number of people in lineup (default = 6)}
}
\value{
A list containing:
  \itemize{
    \item by_condition: List of calibration results for each condition combination
    \item condition_summary: Dataframe summarizing C, O/U, NRI across conditions
  }
}
\description{
Computes calibration analysis separately for different experimental conditions.
Useful for examining how calibration varies across lineup instructions, foil
similarity, or other system/estimator variables.
}
\details{
This function splits the data by the specified condition variables and computes
calibration statistics separately for each combination. Useful for examining
questions like "Does calibration improve with biased vs unbiased instructions?"
or "How does foil similarity affect over/underconfidence?"
}
\references{
Brewer, N., & Wells, G. L. (2006). The confidence-accuracy relationship in
eyewitness identification: Effects of lineup instructions, foil similarity,
and target-absent base rates. \emph{Journal of Experimental Psychology:
Applied, 12}(1), 11-30.
}
