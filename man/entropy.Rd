% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eig_functions.R
\name{entropy}
\alias{entropy}
\title{Compute Shannon Entropy}
\usage{
entropy(p, base = 2)
}
\arguments{
\item{p}{Probability value (between 0 and 1)}

\item{base}{Logarithm base (default = 2 for bits)}
}
\value{
Shannon entropy in bits (if base = 2)
}
\description{
Helper function to compute Shannon entropy for a probability value.
Entropy measures uncertainty about guilt/innocence.
}
\details{
Entropy is computed as: H(p) = -[p*log(p) + (1-p)*log(1-p)]
When p is 0 or 1 (certainty), entropy is 0.
Maximum entropy (1 bit) occurs at p = 0.5 (maximum uncertainty).
}
\keyword{internal}
